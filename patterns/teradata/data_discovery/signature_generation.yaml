# === METADATA START ===
name: signature_generation
title: "Column Signature Generation"
description: |
  Generate statistical signatures for data columns using Teradata's SIGNATURE() User-Defined Aggregate.
  A signature is a compact (60KB) statistical summary containing:
  - Basic statistics (min/max, population, null counts)
  - Value distribution (frequency histogram or random sample)
  - HyperLogLog sketch for distinct count estimation

  **WHAT IS A SIGNATURE?**
  A SIGNATURE is a UDT (User-Defined Type) that captures the "fingerprint" of a column's data:
  - For low-cardinality columns: frequency distribution of all values
  - For high-cardinality columns: random sample + HyperLogLog sketch
  - Works with any data type (INTEGER, VARCHAR, DATE, FLOAT, etc.)

  **USE CASES:**
  - Data profiling and discovery
  - Finding similar columns across tables
  - Detecting keys and foreign keys
  - Identifying domains (SKUs, locations, names, etc.)
  - Schema matching and data integration

  **REQUIREMENTS:**
  Requires SIGNATURE UDT and SIGNATURE() UDA from semantic-mapping project.
  Install with: CREATE_Extensions.sql from semantic-mapping repository.

  **CRITICAL: Schema Requirements**
  Call get_tables() to verify target columns exist before generating signatures.
  Create SIGNATURES warehouse table to store results.

category: data_discovery
difficulty: advanced
teradata_function: SIGNATURE, UDA
# === METADATA END ===

# === USE_CASES START ===
use_cases:
  - Profile columns across entire database
  - Generate signatures for data discovery
  - Create "data fingerprints" for comparison
  - Build signature warehouse for analysis
  - Support key/foreign key detection
  - Enable domain discovery across tables
  - Schema matching and data integration
# === USE_CASES END ===

# === PARAMETERS START ===
parameters:
  - name: database
    type: string
    required: true
    description: "Database containing tables to profile"
    example: "semantic_data"

  - name: table
    type: string
    required: false
    description: "Specific table to profile (optional, profiles all if omitted)"
    example: "customers"

  - name: column
    type: string
    required: false
    description: "Specific column to profile (optional)"
    example: "customer_id"
# === PARAMETERS END ===

# === TEMPLATES START ===
templates:
  create_signature_warehouse:
    description: "Create table to store column signatures"
    sql: |
      -- Create SIGNATURES warehouse table
      CREATE MULTISET TABLE {{database}}.SIGNATURES (
        ID INTEGER GENERATED BY DEFAULT AS IDENTITY
          (START WITH 1 INCREMENT BY 1 MINVALUE 0 MAXVALUE 2147483647),
        TABLE_NAME VARCHAR(128) NOT NULL,
        COLUMN_NAME VARCHAR(128) NOT NULL,
        COLUMN_TYPE VARCHAR(8) NOT NULL,
        ROW_COUNT BIGINT NOT NULL,
        VALUE_COUNT BIGINT NOT NULL,
        DISTINCT_CNT BIGINT NULL DEFAULT NULL,
        SIG_DATA SIGNATURE NOT NULL,
        CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
      PRIMARY INDEX (TABLE_NAME, COLUMN_NAME);

      GRANT ALL ON {{database}}.SIGNATURES TO PUBLIC;

  single_column_signature:
    description: "Generate signature for single column"
    sql: |
      -- Generate signature for {{table}}.{{column}}
      INSERT INTO {{database}}.SIGNATURES
        (TABLE_NAME, COLUMN_NAME, COLUMN_TYPE, ROW_COUNT, VALUE_COUNT, DISTINCT_CNT, SIG_DATA)
      SELECT
        '{{table}}' AS TABLE_NAME,
        '{{column}}' AS COLUMN_NAME,
        '{{column_type}}' AS COLUMN_TYPE,
        COUNT(*) AS ROW_COUNT,
        COUNT(DATA."{{column}}") AS VALUE_COUNT,
        COUNT(DISTINCT DATA."{{column}}") AS DISTINCT_CNT,
        UDFS.SIGNATURE(
          {{if eq .column_type "CV"}}
          UPPER(DATA."{{column}}")
          {{else}}
          DATA."{{column}}"
          {{end}}
        ) AS SIG_DATA
      FROM {{database}}.{{table}} AS DATA;

  generate_signature_queries:
    description: "Generate INSERT queries for all columns in database"
    sql: |
      -- Generate signature queries for all columns
      SELECT
        'INSERT INTO {{database}}.SIGNATURES ' ||
        '(TABLE_NAME, COLUMN_NAME, COLUMN_TYPE, ROW_COUNT, VALUE_COUNT, DISTINCT_CNT, SIG_DATA) ' ||
        'SELECT ' ||
        '''' || RTRIM(TV.TableName) || ''' AS TABLE_NAME, ' ||
        '''' || RTRIM(COL.ColumnName) || ''' AS COLUMN_NAME, ' ||
        '''' || RTRIM(COL.ColumnType) || ''' AS COLUMN_TYPE, ' ||
        'COUNT(*) AS ROW_COUNT, ' ||
        'COUNT(DATA."' || RTRIM(COL.ColumnName) || '") AS VALUE_COUNT, ' ||
        'COUNT(DISTINCT DATA."' || RTRIM(COL.ColumnName) || '") AS DISTINCT_CNT, ' ||
        'UDFS.SIGNATURE(' ||
        CASE COL.ColumnType
          WHEN 'CV' THEN 'UPPER(DATA."' || RTRIM(COL.ColumnName) || '")'
          ELSE 'DATA."' || RTRIM(COL.ColumnName) || '"'
        END || ') AS SIG_DATA ' ||
        'FROM "{{database}}"."' || RTRIM(TV.TableName) || '" AS DATA;' AS signature_query
      FROM DBC.TablesV AS TV
      JOIN DBC.ColumnsV AS COL
        ON TV.DatabaseName = COL.DatabaseName
        AND TV.TableName = COL.TableName
      WHERE TV.DatabaseName = '{{database}}'
        AND TV.TableKind = 'T'
        {{if .table}}AND TV.TableName = '{{table}}'{{end}}
        AND COL.ColumnLength < 128  -- Skip large text columns
      ORDER BY TV.TableName, COL.ColumnId;

  query_signature_json:
    description: "View signature as JSON for inspection"
    sql: |
      -- View signature as JSON
      SELECT
        TABLE_NAME,
        COLUMN_NAME,
        COLUMN_TYPE,
        ROW_COUNT,
        VALUE_COUNT,
        DISTINCT_CNT,
        UDFS.Signature_to_JSON(SIG_DATA) AS signature_json
      FROM {{database}}.SIGNATURES
      WHERE TABLE_NAME = '{{table}}'
        {{if .column}}AND COLUMN_NAME = '{{column}}'{{end}};

  signature_statistics:
    description: "Extract key statistics from signatures"
    sql: |
      -- Extract statistics from signatures
      SELECT
        TABLE_NAME,
        COLUMN_NAME,
        COLUMN_TYPE,
        ROW_COUNT,
        VALUE_COUNT,
        DISTINCT_CNT,
        UDFS.Population(SIG_DATA) AS population,
        UDFS.Null_Count(SIG_DATA) AS null_count,
        UDFS.Count_Estimate(SIG_DATA) AS estimated_distinct,
        UDFS.DC_Estimate_Method(SIG_DATA) AS estimate_method,
        CAST(UDFS.Count_Estimate(SIG_DATA) AS DOUBLE PRECISION) /
          NULLIFZERO(CAST(ROW_COUNT AS DOUBLE PRECISION)) AS keyness
      FROM {{database}}.SIGNATURES
      WHERE TABLE_NAME = '{{table}}'
      ORDER BY keyness DESC;
# === TEMPLATES END ===

# === EXAMPLES START ===
examples:
  - name: "Generate signatures for entire database"
    parameters:
      database: "semantic_data"
    expected_result: |
      Step 1: Create SIGNATURES warehouse
      ```sql
      CREATE TABLE semantic_data.SIGNATURES (...);
      ```

      Step 2: Generate queries for all columns
      Result: 676 INSERT statements generated for all columns

      Step 3: Execute signature generation
      ```sql
      INSERT INTO SIGNATURES SELECT ... UDFS.SIGNATURE(customer_id) ...
      INSERT INTO SIGNATURES SELECT ... UDFS.SIGNATURE(order_date) ...
      ... (676 total queries)
      ```

      Step 4: Verify signatures created
      ```sql
      SELECT COUNT(*) FROM SIGNATURES;
      -- Result: 676 signatures
      ```

  - name: "Profile single table"
    parameters:
      database: "sales"
      table: "customers"
    expected_result: |
      Signatures generated for customers table:

      | TABLE_NAME | COLUMN_NAME  | ROW_COUNT | DISTINCT_CNT | KEYNESS |
      |------------|--------------|-----------|--------------|---------|
      | customers  | customer_id  | 50000     | 50000        | 1.00    |
      | customers  | email        | 50000     | 49876        | 0.998   |
      | customers  | state        | 50000     | 50           | 0.001   |
      | customers  | signup_date  | 50000     | 1825         | 0.037   |

      Interpretation:
      - customer_id: Perfect key (keyness = 1.0)
      - email: Nearly unique (keyness = 0.998)
      - state: Low cardinality domain (50 distinct values)
      - signup_date: Temporal dimension (1825 days â‰ˆ 5 years)

  - name: "Inspect signature details as JSON"
    parameters:
      database: "semantic_data"
      table: "products"
      column: "category"
    expected_result: |
      Signature JSON for products.category:

      ```json
      {
        "type": "CV",
        "population": 10000,
        "null_count": 0,
        "distinct_estimate": 12,
        "estimate_method": "EXACT",
        "min_value": "AUTOMOTIVE",
        "max_value": "TOYS",
        "sample": {
          "ELECTRONICS": 2543,
          "CLOTHING": 1876,
          "HOME": 1654,
          "TOYS": 1432,
          "AUTOMOTIVE": 982,
          ...
        },
        "hll_sketch": "base64_encoded_hyperloglog_data"
      }
      ```

      This shows:
      - 12 distinct categories (low cardinality = domain)
      - Complete frequency distribution available
      - No null values
      - Good candidate for dimension table
# === EXAMPLES END ===

# === BEST_PRACTICES START ===
best_practices: |
  ## Signature Generation Best Practices

  ### 1. Install Semantic-Mapping Extensions First
  ```sql
  -- Run from semantic-mapping repository
  .RUN FILE = Create_Extensions.sql
  ```
  This installs SIGNATURE UDT and all UDFs.

  ### 2. Create SIGNATURES Warehouse Once
  Store all signatures in centralized table:
  ```sql
  CREATE TABLE SIGNATURES (
    ID INTEGER GENERATED BY DEFAULT AS IDENTITY,
    TABLE_NAME VARCHAR(128),
    COLUMN_NAME VARCHAR(128),
    SIG_DATA SIGNATURE,
    ...
  );
  ```

  ### 3. Use UPPER() for VARCHAR Columns
  Normalize case for better comparison:
  ```sql
  UDFS.SIGNATURE(UPPER(column_name))  -- For CV type
  UDFS.SIGNATURE(column_name)         -- For I, F, DA types
  ```

  ### 4. Skip Large Text Columns
  Filter out columns > 128 bytes:
  ```sql
  WHERE COL.ColumnLength < 128
  ```
  Free-text columns don't produce useful signatures.

  ### 5. Generate Queries, Don't Hand-Write
  Use meta-query to generate signature INSERT statements:
  ```sql
  SELECT 'INSERT INTO SIGNATURES ...' || ...
  FROM DBC.TablesV JOIN DBC.ColumnsV ...
  ```

  ### 6. Batch Signature Generation
  For large databases, generate in batches:
  - Generate queries: `bteq < Generate_Signature_Aggregate_Queries.sql > queries.sql`
  - Execute in parallel: Split queries.sql into chunks, run concurrently

  ### 7. Extract Statistics for Analysis
  Key metrics from signatures:
  - **Keyness**: `COUNT_ESTIMATE(sig) / ROW_COUNT` (1.0 = perfect key)
  - **Null percentage**: `NULL_COUNT(sig) / POPULATION(sig)`
  - **IsSurrogate**: Detect synthetic keys automatically

  ### 8. Memory Layers for Signature Management
  - **Kernel Layer**: Cache SIGNATURES table schema and commonly-used signature functions
  - **L1 Cache**: Keep recent signature queries (last 5-8 tables profiled) for pattern reuse
  - **L2 Compressed**: Archive signature metadata showing keyness trends over time
  - **Swap Layer**: Store complete signature history; use recall_conversation to compare current column profiles against baseline from months ago
  This enables tracking data drift and identifying when column characteristics change.
# === BEST_PRACTICES END ===

# === COMMON_ERRORS START ===
common_errors:
  - error: "SIGNATURE type not found"
    cause: "Semantic-mapping UDT/UDF extensions not installed"
    solution: "Run Create_Extensions.sql from semantic-mapping repository to install SIGNATURE type and functions"

  - error: "UDFS.SIGNATURE function not found"
    cause: "UDF library not loaded or database UDFS does not exist"
    solution: "Verify UDFS database exists: SELECT * FROM DBC.DatabasesV WHERE DatabaseName = 'UDFS'"

  - error: "Signature generation very slow on large columns"
    cause: "Processing free-text or BLOB columns"
    solution: "Filter out large columns: WHERE COL.ColumnLength < 128"

  - error: "Out of memory during signature generation"
    cause: "Table has billions of rows, signature sampling exhausted memory"
    solution: "Sample data first: UDFS.SIGNATURE(column) FROM table SAMPLE 1000000"
# === COMMON_ERRORS END ===

# === RELATED_PATTERNS START ===
related_patterns:
  - key_detection  # Use signatures to find primary keys
  - foreign_key_detection  # Use signatures to find FK relationships
  - column_similarity  # Compare signatures using distance metrics
  - data_profiling  # Extract statistics from signatures
# === RELATED_PATTERNS END ===

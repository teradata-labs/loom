# === METADATA START ===
name: missing_index_analysis
title: "Missing Index Analysis"
description: "Analyzes query patterns to recommend missing indexes by examining query plans, identifying sequential scans, and suggesting optimal index configurations"
category: analytics
difficulty: intermediate
backend_type: postgres
priority: 90
# === METADATA END ===

# === USE_CASES START ===
use_cases:
  - "Identify missing indexes on JOIN columns"
  - "Recommend indexes for WHERE filters"
  - "Optimize ORDER BY and GROUP BY queries"
  - "Detect sequential scans on large tables"
  - "Improve query performance by 10-100x"
  - "Reduce buffer reads and I/O"
  - "Find unused indexes wasting space"
# === USE_CASES END ===

# === PARAMETERS START ===
parameters:
  - name: query
    type: string
    required: true
    description: "SQL query to analyze"
    example: "SELECT * FROM orders WHERE status = 'pending'"

  - name: table_name
    type: string
    required: false
    description: "Specific table to analyze for missing indexes"
    example: "orders"

  - name: schema_name
    type: string
    required: false
    description: "Schema name (defaults to public)"
    default: "public"
    example: "public"
# === PARAMETERS END ===

# === TEMPLATES START ===
templates:
  analysis: |
    -- Missing Index Analysis for Query
    -- Query: {{.query}}

    -- Step 1: Get query execution plan with detailed metrics
    EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
    {{.query}};

    -- Step 2: Identify tables with sequential scans
    -- Look for "Seq Scan" nodes in the plan - these indicate missing indexes

    -- Step 3: Check existing indexes on tables involved
    SELECT
      schemaname,
      tablename,
      indexname,
      indexdef
    FROM pg_indexes
    WHERE schemaname = '{{.schema_name}}'
      AND tablename IN (
        -- Extract table names from query
        SELECT DISTINCT tablename
        FROM pg_tables
        WHERE schemaname = '{{.schema_name}}'
      )
    ORDER BY tablename, indexname;

    -- Step 4: Analyze column usage statistics
    SELECT
      schemaname,
      tablename,
      attname AS column_name,
      n_distinct,
      correlation,
      null_frac
    FROM pg_stats
    WHERE schemaname = '{{.schema_name}}'
    ORDER BY tablename, attname;

  index_recommendation: |
    -- Index Recommendations
    -- Based on query analysis, create indexes for columns in:
    -- 1. WHERE clauses (equality and range filters)
    -- 2. JOIN conditions (foreign keys)
    -- 3. ORDER BY clauses
    -- 4. GROUP BY clauses

    -- Example recommendations (customize based on actual query analysis):

    -- For WHERE equality filters on high-cardinality columns:
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_column_name
      ON {{.schema_name}}.{{.table_name}}(column_name);

    -- For WHERE range queries (e.g., dates, amounts):
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_created_at
      ON {{.schema_name}}.{{.table_name}}(created_at);

    -- For foreign key JOINs:
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_fk_id
      ON {{.schema_name}}.{{.table_name}}(foreign_key_id);

    -- For composite WHERE conditions (order matters - most selective first):
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_composite
      ON {{.schema_name}}.{{.table_name}}(high_selectivity_col, low_selectivity_col);

    -- For ORDER BY optimization (covering index):
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_ordering
      ON {{.schema_name}}.{{.table_name}}(order_column)
      INCLUDE (frequently_selected_columns);

    -- For partial indexes (when filtering on specific values frequently):
    CREATE INDEX IF NOT EXISTS idx_{{.table_name}}_partial
      ON {{.schema_name}}.{{.table_name}}(column_name)
      WHERE status = 'active';

  system_analysis: |
    -- System-wide missing index detection
    -- Identifies tables with frequent sequential scans

    -- Tables with high sequential scan counts
    SELECT
      schemaname,
      tablename,
      seq_scan,
      seq_tup_read,
      idx_scan,
      n_live_tup,
      pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
      CASE
        WHEN seq_scan = 0 THEN 0
        ELSE ROUND((seq_tup_read::numeric / seq_scan), 2)
      END AS avg_rows_per_seq_scan
    FROM pg_stat_user_tables
    WHERE schemaname = '{{.schema_name}}'
      AND seq_scan > 0
      AND n_live_tup > 1000  -- Focus on tables with data
    ORDER BY seq_scan DESC, seq_tup_read DESC
    LIMIT 20;

    -- Unused or rarely used indexes (candidates for removal)
    SELECT
      schemaname,
      tablename,
      indexname,
      idx_scan,
      idx_tup_read,
      idx_tup_fetch,
      pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
    FROM pg_stat_user_indexes
    WHERE schemaname = '{{.schema_name}}'
      AND idx_scan < 10  -- Used fewer than 10 times
    ORDER BY pg_relation_size(indexrelid) DESC
    LIMIT 20;

  verification: |
    -- Verify index effectiveness after creation

    -- Step 1: Re-run EXPLAIN to confirm index usage
    EXPLAIN (ANALYZE, BUFFERS)
    {{.query}};

    -- Look for "Index Scan" or "Bitmap Index Scan" instead of "Seq Scan"

    -- Step 2: Compare metrics before/after
    -- Before: Planning time, Execution time, Buffers (shared hit/read)
    -- After:  Should show reduced execution time and buffer reads

    -- Step 3: Check index statistics
    SELECT
      schemaname,
      tablename,
      indexname,
      idx_scan AS times_used,
      idx_tup_read AS tuples_read,
      idx_tup_fetch AS tuples_fetched,
      pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
    FROM pg_stat_user_indexes
    WHERE schemaname = '{{.schema_name}}'
      AND tablename = '{{.table_name}}'
    ORDER BY indexname;

    -- Step 4: Validate performance improvement
    -- Expected: Execution time reduced by 10-100x for large tables
    -- Expected: Buffer reads reduced significantly (more shared hits)
# === TEMPLATES END ===

# === EXAMPLES START ===
examples:
  - name: "WHERE clause on unindexed status column"
    parameters:
      query: "SELECT * FROM orders WHERE status = 'pending'"
      table_name: "orders"
      schema_name: "public"
    expected_result: |
      Analysis shows sequential scan on orders table (100,000 rows scanned).

      Recommendation:
      CREATE INDEX idx_orders_status ON orders(status);

      Expected improvement:
      - Before: 45ms execution, 8000 buffer reads
      - After:  2ms execution, 50 buffer reads (90% faster)
      - Index size: ~2 MB for 100K rows

  - name: "JOIN on unindexed foreign key"
    parameters:
      query: "SELECT o.*, u.name FROM orders o JOIN users u ON o.user_id = u.id WHERE o.created_at > '2024-01-01'"
      table_name: "orders"
      schema_name: "public"
    expected_result: |
      Analysis shows:
      1. Sequential scan on orders (no index on created_at)
      2. No index on orders.user_id (foreign key)

      Recommendations:
      CREATE INDEX idx_orders_created_at ON orders(created_at);
      CREATE INDEX idx_orders_user_id ON orders(user_id);

      Expected improvement:
      - Before: 850ms execution, nested loop join with seq scans
      - After:  35ms execution, hash join with index scans (96% faster)

  - name: "ORDER BY on unindexed column"
    parameters:
      query: "SELECT * FROM products ORDER BY price DESC LIMIT 10"
      table_name: "products"
      schema_name: "public"
    expected_result: |
      Analysis shows sequential scan + sort operation (50,000 rows).

      Recommendation:
      CREATE INDEX idx_products_price_desc ON products(price DESC);

      Expected improvement:
      - Before: 120ms execution (seq scan + sort)
      - After:  5ms execution (index scan only, no sort needed)
      - 96% faster with backward index scan
# === EXAMPLES END ===

# === BEST_PRACTICES START ===
best_practices: |
  ## Missing Index Analysis Best Practices

  ### 1. Analyze Query Plans First
  Always run EXPLAIN (ANALYZE, BUFFERS) before creating indexes:
  - Look for "Seq Scan" on large tables (>1000 rows)
  - Check buffer reads (high reads = slow query)
  - Identify filtering, joining, and sorting operations

  ### 2. Index Selectively
  **Don't over-index!** Each index:
  - Slows down INSERT/UPDATE/DELETE operations
  - Consumes disk space (~10-30% of table size)
  - Requires maintenance (VACUUM, statistics updates)

  **Index these columns:**
  - Primary keys (automatic)
  - Foreign keys (NOT automatic in Postgres!)
  - WHERE clause filters (high selectivity)
  - JOIN conditions
  - ORDER BY columns (frequent queries)

  **Don't index:**
  - Small tables (<1000 rows)
  - Low-cardinality columns (e.g., boolean, status with 2-3 values)
  - Columns rarely used in queries
  - Columns with high UPDATE frequency

  ### 3. Column Order in Composite Indexes
  Most selective column first:
  ```sql
  -- Good: status has 10 values, user_id has 10,000 values
  CREATE INDEX idx_orders_user_status ON orders(user_id, status);

  -- Bad: status is not selective enough to be first
  CREATE INDEX idx_orders_status_user ON orders(status, user_id);
  ```

  ### 4. Use Partial Indexes for Frequent Filters
  When queries frequently filter on specific values:
  ```sql
  -- If 90% of queries filter WHERE status = 'active'
  CREATE INDEX idx_orders_active ON orders(user_id, created_at)
    WHERE status = 'active';

  -- Much smaller than full index, faster lookups
  ```

  ### 5. Covering Indexes for SELECT Performance
  Include frequently-selected columns to avoid table lookups:
  ```sql
  CREATE INDEX idx_orders_user_covering
    ON orders(user_id)
    INCLUDE (status, total_amount, created_at);

  -- Query can be satisfied entirely from index (Index Only Scan)
  ```

  ### 6. Monitor Index Usage
  ```sql
  -- Find unused indexes
  SELECT * FROM pg_stat_user_indexes
  WHERE idx_scan < 10 AND schemaname = 'public'
  ORDER BY pg_relation_size(indexrelid) DESC;

  -- Drop unused indexes wasting space
  DROP INDEX IF EXISTS idx_rarely_used;
  ```

  ### 7. Index Maintenance
  Postgres requires periodic maintenance:
  ```sql
  -- Rebuild bloated indexes
  REINDEX INDEX idx_name;

  -- Update statistics for query planner
  ANALYZE table_name;

  -- Or enable autovacuum (recommended)
  ```

  ### 8. Test Before Production
  - Create indexes on dev/staging first
  - Use CREATE INDEX CONCURRENTLY to avoid locking (production)
  - Compare EXPLAIN plans before/after
  - Monitor query performance metrics

  ### 9. Consider Expression Indexes
  For queries filtering on computed values:
  ```sql
  -- If queries use: WHERE LOWER(email) = 'test@example.com'
  CREATE INDEX idx_users_email_lower ON users(LOWER(email));
  ```

  ### 10. Memory Layers for Index Analysis
  - **Kernel Layer**: Cache table schemas and existing indexes for quick reference during analysis
  - **L1 Cache**: Keep recent query plans and EXPLAIN results (last 5-10 queries) for comparison
  - **L2 Compressed**: Archive index recommendations and their impact metrics from earlier in the conversation
  - **Swap Layer**: Store complete query performance history for long-running optimization projects; use recall_conversation to compare current performance against baseline metrics from weeks ago
  This reduces redundant EXPLAIN operations and enables tracking index impact across iterative optimization cycles.
# === BEST_PRACTICES END ===

# === RELATED_PATTERNS START ===
related_patterns:
  - join_optimization
  - sequential_scan_detection
  - query_rewrite
  - partition_recommendation
# === RELATED_PATTERNS END ===

validation:
  rules:
    - "Verify column exists in table"
    - "Check if index already exists"
    - "Estimate index size vs benefit"
    - "Confirm query uses index after creation"

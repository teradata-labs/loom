// Copyright Â© 2026 Teradata Corporation - All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        (unknown)
// source: loom/v1/agent_config.proto

package loomv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// LLMRole identifies the purpose/role of an LLM provider within an agent.
// Each role can be backed by a different provider/model optimized for its task.
// Fallback chain: Role-specific LLM -> Agent default LLM -> Server default LLM.
type LLMRole int32

const (
	LLMRole_LLM_ROLE_UNSPECIFIED  LLMRole = 0 // Default: main agent LLM
	LLMRole_LLM_ROLE_AGENT        LLMRole = 1 // Primary reasoning LLM
	LLMRole_LLM_ROLE_JUDGE        LLMRole = 2 // Evaluation operations
	LLMRole_LLM_ROLE_ORCHESTRATOR LLMRole = 3 // Fork-join merge/synthesis
	LLMRole_LLM_ROLE_CLASSIFIER   LLMRole = 4 // Intent classification for pattern selection
	LLMRole_LLM_ROLE_COMPRESSOR   LLMRole = 5 // Memory compression/semantic search reranking
)

// Enum value maps for LLMRole.
var (
	LLMRole_name = map[int32]string{
		0: "LLM_ROLE_UNSPECIFIED",
		1: "LLM_ROLE_AGENT",
		2: "LLM_ROLE_JUDGE",
		3: "LLM_ROLE_ORCHESTRATOR",
		4: "LLM_ROLE_CLASSIFIER",
		5: "LLM_ROLE_COMPRESSOR",
	}
	LLMRole_value = map[string]int32{
		"LLM_ROLE_UNSPECIFIED":  0,
		"LLM_ROLE_AGENT":        1,
		"LLM_ROLE_JUDGE":        2,
		"LLM_ROLE_ORCHESTRATOR": 3,
		"LLM_ROLE_CLASSIFIER":   4,
		"LLM_ROLE_COMPRESSOR":   5,
	}
)

func (x LLMRole) Enum() *LLMRole {
	p := new(LLMRole)
	*p = x
	return p
}

func (x LLMRole) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LLMRole) Descriptor() protoreflect.EnumDescriptor {
	return file_loom_v1_agent_config_proto_enumTypes[0].Descriptor()
}

func (LLMRole) Type() protoreflect.EnumType {
	return &file_loom_v1_agent_config_proto_enumTypes[0]
}

func (x LLMRole) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LLMRole.Descriptor instead.
func (LLMRole) EnumDescriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{0}
}

// WorkloadProfile defines memory compression behavior profiles for different use cases
type WorkloadProfile int32

const (
	WorkloadProfile_WORKLOAD_PROFILE_UNSPECIFIED WorkloadProfile = 0
	// Balanced profile (default): maxL1=8, warning=60%, critical=75%
	// Suitable for general-purpose agents with mixed workloads
	WorkloadProfile_WORKLOAD_PROFILE_BALANCED WorkloadProfile = 1
	// Data-intensive profile: maxL1=5, warning=50%, critical=70%
	// Optimized for agents handling large tool outputs (SQL, file operations)
	WorkloadProfile_WORKLOAD_PROFILE_DATA_INTENSIVE WorkloadProfile = 2
	// Conversational profile: maxL1=12, warning=70%, critical=85%
	// Optimized for chat-heavy agents with minimal tool usage
	WorkloadProfile_WORKLOAD_PROFILE_CONVERSATIONAL WorkloadProfile = 3
)

// Enum value maps for WorkloadProfile.
var (
	WorkloadProfile_name = map[int32]string{
		0: "WORKLOAD_PROFILE_UNSPECIFIED",
		1: "WORKLOAD_PROFILE_BALANCED",
		2: "WORKLOAD_PROFILE_DATA_INTENSIVE",
		3: "WORKLOAD_PROFILE_CONVERSATIONAL",
	}
	WorkloadProfile_value = map[string]int32{
		"WORKLOAD_PROFILE_UNSPECIFIED":    0,
		"WORKLOAD_PROFILE_BALANCED":       1,
		"WORKLOAD_PROFILE_DATA_INTENSIVE": 2,
		"WORKLOAD_PROFILE_CONVERSATIONAL": 3,
	}
)

func (x WorkloadProfile) Enum() *WorkloadProfile {
	p := new(WorkloadProfile)
	*p = x
	return p
}

func (x WorkloadProfile) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (WorkloadProfile) Descriptor() protoreflect.EnumDescriptor {
	return file_loom_v1_agent_config_proto_enumTypes[1].Descriptor()
}

func (WorkloadProfile) Type() protoreflect.EnumType {
	return &file_loom_v1_agent_config_proto_enumTypes[1]
}

func (x WorkloadProfile) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use WorkloadProfile.Descriptor instead.
func (WorkloadProfile) EnumDescriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{1}
}

// SpawnTriggerType enumerates trigger conditions
type SpawnTriggerType int32

const (
	SpawnTriggerType_SPAWN_TRIGGER_TYPE_UNSPECIFIED SpawnTriggerType = 0
	// Spawn when consensus is not reached in debate/swarm
	SpawnTriggerType_CONSENSUS_NOT_REACHED SpawnTriggerType = 1
	// Spawn when average confidence falls below threshold
	SpawnTriggerType_CONFIDENCE_BELOW SpawnTriggerType = 2
	// Spawn when voting results in a tie
	SpawnTriggerType_TIE_DETECTED SpawnTriggerType = 3
	// Spawn when agent explicitly requests escalation
	SpawnTriggerType_ESCALATION_REQUESTED SpawnTriggerType = 4
	// Spawn unconditionally (for testing)
	SpawnTriggerType_ALWAYS SpawnTriggerType = 5
	// Custom condition evaluated at runtime
	SpawnTriggerType_CUSTOM SpawnTriggerType = 6
)

// Enum value maps for SpawnTriggerType.
var (
	SpawnTriggerType_name = map[int32]string{
		0: "SPAWN_TRIGGER_TYPE_UNSPECIFIED",
		1: "CONSENSUS_NOT_REACHED",
		2: "CONFIDENCE_BELOW",
		3: "TIE_DETECTED",
		4: "ESCALATION_REQUESTED",
		5: "ALWAYS",
		6: "CUSTOM",
	}
	SpawnTriggerType_value = map[string]int32{
		"SPAWN_TRIGGER_TYPE_UNSPECIFIED": 0,
		"CONSENSUS_NOT_REACHED":          1,
		"CONFIDENCE_BELOW":               2,
		"TIE_DETECTED":                   3,
		"ESCALATION_REQUESTED":           4,
		"ALWAYS":                         5,
		"CUSTOM":                         6,
	}
)

func (x SpawnTriggerType) Enum() *SpawnTriggerType {
	p := new(SpawnTriggerType)
	*p = x
	return p
}

func (x SpawnTriggerType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SpawnTriggerType) Descriptor() protoreflect.EnumDescriptor {
	return file_loom_v1_agent_config_proto_enumTypes[2].Descriptor()
}

func (SpawnTriggerType) Type() protoreflect.EnumType {
	return &file_loom_v1_agent_config_proto_enumTypes[2]
}

func (x SpawnTriggerType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SpawnTriggerType.Descriptor instead.
func (SpawnTriggerType) EnumDescriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{2}
}

// AgentConfig defines a complete agent configuration.
// This message represents a declarative agent specification that can be
// loaded from YAML files or created programmatically.
type AgentConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique name for the agent (e.g., "sql_expert", "security_analyst")
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Human-readable description of the agent's purpose
	Description string `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	// LLM configuration
	Llm *LLMConfig `protobuf:"bytes,3,opt,name=llm,proto3" json:"llm,omitempty"`
	// System prompt that defines the agent's behavior and persona
	SystemPrompt string `protobuf:"bytes,4,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"`
	// Tools configuration
	Tools *ToolsConfig `protobuf:"bytes,5,opt,name=tools,proto3" json:"tools,omitempty"`
	// Memory/session storage configuration
	Memory *MemoryConfig `protobuf:"bytes,6,opt,name=memory,proto3" json:"memory,omitempty"`
	// Behavior constraints and limits
	Behavior *BehaviorConfig `protobuf:"bytes,7,opt,name=behavior,proto3" json:"behavior,omitempty"`
	// Optional metadata (author, version, tags, etc.)
	Metadata map[string]string `protobuf:"bytes,8,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Ephemeral agent policies - defines which agents can be spawned dynamically
	EphemeralAgents []*EphemeralAgentPolicy `protobuf:"bytes,9,rep,name=ephemeral_agents,json=ephemeralAgents,proto3" json:"ephemeral_agents,omitempty"`
	// ROM (Read-Only Memory) identifier for domain-specific knowledge
	// Options:
	//   - "TD" or "teradata": Load Teradata SQL guidance (embedded TD.rom)
	//   - "auto": Auto-detect based on backend configuration (default)
	//   - "": No ROM (empty system prompt only)
	//
	// If not specified, defaults to "auto" which detects ROM from backend path
	Rom string `protobuf:"bytes,10,opt,name=rom,proto3" json:"rom,omitempty"`
	// Automatic finding extraction configuration
	// When enabled, the agent automatically extracts structured findings from tool results
	// using LLM-based semantic analysis. This replaces the manual record_finding tool.
	EnableFindingExtraction bool `protobuf:"varint,11,opt,name=enable_finding_extraction,json=enableFindingExtraction,proto3" json:"enable_finding_extraction,omitempty"` // Default: true
	// Number of tool executions between automatic finding extractions (default: 3)
	// Lower values extract more frequently (higher quality, higher cost)
	// Higher values extract less frequently (lower cost, may miss patterns)
	ExtractionCadence int32 `protobuf:"varint,12,opt,name=extraction_cadence,json=extractionCadence,proto3" json:"extraction_cadence,omitempty"`
	// Maximum number of findings to keep in cache (default: 50)
	// Oldest findings are evicted using LRU when limit is reached
	// Lower values save tokens, higher values preserve more context
	MaxFindings int32 `protobuf:"varint,13,opt,name=max_findings,json=maxFindings,proto3" json:"max_findings,omitempty"`
	// Judge/evaluation override (e.g., Gemini for unbiased evaluation)
	JudgeLlm *LLMConfig `protobuf:"bytes,14,opt,name=judge_llm,json=judgeLlm,proto3" json:"judge_llm,omitempty"`
	// Merge/synthesis override for fork-join orchestration (e.g., fast model for combining results)
	OrchestratorLlm *LLMConfig `protobuf:"bytes,15,opt,name=orchestrator_llm,json=orchestratorLlm,proto3" json:"orchestrator_llm,omitempty"`
	// Intent classification override (e.g., small/fast model like Ollama for pattern selection)
	ClassifierLlm *LLMConfig `protobuf:"bytes,16,opt,name=classifier_llm,json=classifierLlm,proto3" json:"classifier_llm,omitempty"`
	// Memory compression/semantic search reranking override (e.g., Haiku for cost-effective compression)
	CompressorLlm *LLMConfig `protobuf:"bytes,17,opt,name=compressor_llm,json=compressorLlm,proto3" json:"compressor_llm,omitempty"`
	// Named provider override: use this named entry from the global provider pool instead of llm.
	// Must be a name defined in the server's providers list.
	ActiveProvider string `protobuf:"bytes,18,opt,name=active_provider,json=activeProvider,proto3" json:"active_provider,omitempty"`
	// Restrict this agent to only use providers in this list (subset of global pool).
	// Empty means all pool providers are allowed.
	AllowedProviders []string `protobuf:"bytes,19,rep,name=allowed_providers,json=allowedProviders,proto3" json:"allowed_providers,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *AgentConfig) Reset() {
	*x = AgentConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AgentConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AgentConfig) ProtoMessage() {}

func (x *AgentConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AgentConfig.ProtoReflect.Descriptor instead.
func (*AgentConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{0}
}

func (x *AgentConfig) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *AgentConfig) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *AgentConfig) GetLlm() *LLMConfig {
	if x != nil {
		return x.Llm
	}
	return nil
}

func (x *AgentConfig) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *AgentConfig) GetTools() *ToolsConfig {
	if x != nil {
		return x.Tools
	}
	return nil
}

func (x *AgentConfig) GetMemory() *MemoryConfig {
	if x != nil {
		return x.Memory
	}
	return nil
}

func (x *AgentConfig) GetBehavior() *BehaviorConfig {
	if x != nil {
		return x.Behavior
	}
	return nil
}

func (x *AgentConfig) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *AgentConfig) GetEphemeralAgents() []*EphemeralAgentPolicy {
	if x != nil {
		return x.EphemeralAgents
	}
	return nil
}

func (x *AgentConfig) GetRom() string {
	if x != nil {
		return x.Rom
	}
	return ""
}

func (x *AgentConfig) GetEnableFindingExtraction() bool {
	if x != nil {
		return x.EnableFindingExtraction
	}
	return false
}

func (x *AgentConfig) GetExtractionCadence() int32 {
	if x != nil {
		return x.ExtractionCadence
	}
	return 0
}

func (x *AgentConfig) GetMaxFindings() int32 {
	if x != nil {
		return x.MaxFindings
	}
	return 0
}

func (x *AgentConfig) GetJudgeLlm() *LLMConfig {
	if x != nil {
		return x.JudgeLlm
	}
	return nil
}

func (x *AgentConfig) GetOrchestratorLlm() *LLMConfig {
	if x != nil {
		return x.OrchestratorLlm
	}
	return nil
}

func (x *AgentConfig) GetClassifierLlm() *LLMConfig {
	if x != nil {
		return x.ClassifierLlm
	}
	return nil
}

func (x *AgentConfig) GetCompressorLlm() *LLMConfig {
	if x != nil {
		return x.CompressorLlm
	}
	return nil
}

func (x *AgentConfig) GetActiveProvider() string {
	if x != nil {
		return x.ActiveProvider
	}
	return ""
}

func (x *AgentConfig) GetAllowedProviders() []string {
	if x != nil {
		return x.AllowedProviders
	}
	return nil
}

// ProviderEntry is a named LLM configuration in the global provider pool.
type ProviderEntry struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Alias for this provider, e.g. "claude-opus", "llama-local"
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Full LLM config for this provider
	Config        *LLMConfig `protobuf:"bytes,2,opt,name=config,proto3" json:"config,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ProviderEntry) Reset() {
	*x = ProviderEntry{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ProviderEntry) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ProviderEntry) ProtoMessage() {}

func (x *ProviderEntry) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ProviderEntry.ProtoReflect.Descriptor instead.
func (*ProviderEntry) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{1}
}

func (x *ProviderEntry) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ProviderEntry) GetConfig() *LLMConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

// ProviderPool is the global pool of named LLM providers (server-level).
type ProviderPool struct {
	state     protoimpl.MessageState `protogen:"open.v1"`
	Providers []*ProviderEntry       `protobuf:"bytes,1,rep,name=providers,proto3" json:"providers,omitempty"`
	// Name of the currently active provider
	Active        string `protobuf:"bytes,2,opt,name=active,proto3" json:"active,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ProviderPool) Reset() {
	*x = ProviderPool{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ProviderPool) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ProviderPool) ProtoMessage() {}

func (x *ProviderPool) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ProviderPool.ProtoReflect.Descriptor instead.
func (*ProviderPool) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{2}
}

func (x *ProviderPool) GetProviders() []*ProviderEntry {
	if x != nil {
		return x.Providers
	}
	return nil
}

func (x *ProviderPool) GetActive() string {
	if x != nil {
		return x.Active
	}
	return ""
}

// LLMConfig configures the language model provider and parameters
type LLMConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Provider name: "anthropic", "bedrock", "ollama"
	Provider string `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"`
	// Model identifier (e.g., "claude-3-5-sonnet-20241022-v2:0")
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// Temperature (0.0-1.0) controls randomness
	Temperature float32 `protobuf:"fixed32,3,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// Maximum tokens in response
	MaxTokens int32 `protobuf:"varint,4,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// Stop sequences to end generation
	StopSequences []string `protobuf:"bytes,5,rep,name=stop_sequences,json=stopSequences,proto3" json:"stop_sequences,omitempty"`
	// Top-p sampling parameter (0.0-1.0)
	TopP float32 `protobuf:"fixed32,6,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	// Top-k sampling parameter
	TopK int32 `protobuf:"varint,7,opt,name=top_k,json=topK,proto3" json:"top_k,omitempty"`
	// Maximum context window tokens supported by the model
	// If not set, will be auto-detected from model name or use provider default
	// Examples: Claude Sonnet 4.5 = 200000, Llama 3.1 = 128000, Mistral = 32000
	MaxContextTokens int32 `protobuf:"varint,8,opt,name=max_context_tokens,json=maxContextTokens,proto3" json:"max_context_tokens,omitempty"`
	// Tokens reserved for model output (typically 10% of max_context_tokens)
	// If not set, will be calculated as max_context_tokens * 0.1
	// Examples: Claude (200K) = 20000, Llama (128K) = 12800, Mistral (32K) = 3200
	ReservedOutputTokens int32 `protobuf:"varint,9,opt,name=reserved_output_tokens,json=reservedOutputTokens,proto3" json:"reserved_output_tokens,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *LLMConfig) Reset() {
	*x = LLMConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LLMConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LLMConfig) ProtoMessage() {}

func (x *LLMConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LLMConfig.ProtoReflect.Descriptor instead.
func (*LLMConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{3}
}

func (x *LLMConfig) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *LLMConfig) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *LLMConfig) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *LLMConfig) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *LLMConfig) GetStopSequences() []string {
	if x != nil {
		return x.StopSequences
	}
	return nil
}

func (x *LLMConfig) GetTopP() float32 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *LLMConfig) GetTopK() int32 {
	if x != nil {
		return x.TopK
	}
	return 0
}

func (x *LLMConfig) GetMaxContextTokens() int32 {
	if x != nil {
		return x.MaxContextTokens
	}
	return 0
}

func (x *LLMConfig) GetReservedOutputTokens() int32 {
	if x != nil {
		return x.ReservedOutputTokens
	}
	return 0
}

// ToolsConfig defines tools available to the agent
type ToolsConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// MCP (Model Context Protocol) tools from servers
	Mcp []*MCPToolConfig `protobuf:"bytes,1,rep,name=mcp,proto3" json:"mcp,omitempty"`
	// Custom tool implementations
	Custom []*CustomToolConfig `protobuf:"bytes,2,rep,name=custom,proto3" json:"custom,omitempty"`
	// Built-in tools (e.g., "web_search", "calculator")
	Builtin       []string `protobuf:"bytes,3,rep,name=builtin,proto3" json:"builtin,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolsConfig) Reset() {
	*x = ToolsConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolsConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolsConfig) ProtoMessage() {}

func (x *ToolsConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolsConfig.ProtoReflect.Descriptor instead.
func (*ToolsConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{4}
}

func (x *ToolsConfig) GetMcp() []*MCPToolConfig {
	if x != nil {
		return x.Mcp
	}
	return nil
}

func (x *ToolsConfig) GetCustom() []*CustomToolConfig {
	if x != nil {
		return x.Custom
	}
	return nil
}

func (x *ToolsConfig) GetBuiltin() []string {
	if x != nil {
		return x.Builtin
	}
	return nil
}

// MCPToolConfig specifies tools from an MCP server
type MCPToolConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// MCP server name (must be configured in MCP manager)
	Server string `protobuf:"bytes,1,opt,name=server,proto3" json:"server,omitempty"`
	// Specific tool names to enable (empty = all tools from server)
	Tools         []string `protobuf:"bytes,2,rep,name=tools,proto3" json:"tools,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MCPToolConfig) Reset() {
	*x = MCPToolConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MCPToolConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MCPToolConfig) ProtoMessage() {}

func (x *MCPToolConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MCPToolConfig.ProtoReflect.Descriptor instead.
func (*MCPToolConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{5}
}

func (x *MCPToolConfig) GetServer() string {
	if x != nil {
		return x.Server
	}
	return ""
}

func (x *MCPToolConfig) GetTools() []string {
	if x != nil {
		return x.Tools
	}
	return nil
}

// CustomToolConfig defines a custom tool implementation
type CustomToolConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Tool name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Path to tool implementation (Go file or plugin)
	Implementation string `protobuf:"bytes,2,opt,name=implementation,proto3" json:"implementation,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *CustomToolConfig) Reset() {
	*x = CustomToolConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CustomToolConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CustomToolConfig) ProtoMessage() {}

func (x *CustomToolConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CustomToolConfig.ProtoReflect.Descriptor instead.
func (*CustomToolConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{6}
}

func (x *CustomToolConfig) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *CustomToolConfig) GetImplementation() string {
	if x != nil {
		return x.Implementation
	}
	return ""
}

// MemoryConfig defines agent memory and session storage
type MemoryConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Storage type: "memory" (in-memory), "sqlite", "postgres"
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// File path for file-based storage (sqlite)
	Path string `protobuf:"bytes,2,opt,name=path,proto3" json:"path,omitempty"`
	// Database DSN for database storage (postgres)
	Dsn string `protobuf:"bytes,3,opt,name=dsn,proto3" json:"dsn,omitempty"`
	// Maximum conversation history to retain
	MaxHistory int32 `protobuf:"varint,4,opt,name=max_history,json=maxHistory,proto3" json:"max_history,omitempty"`
	// Memory compression configuration (conversation history compression)
	MemoryCompression *MemoryCompressionConfig `protobuf:"bytes,5,opt,name=memory_compression,json=memoryCompression,proto3" json:"memory_compression,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *MemoryConfig) Reset() {
	*x = MemoryConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MemoryConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MemoryConfig) ProtoMessage() {}

func (x *MemoryConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MemoryConfig.ProtoReflect.Descriptor instead.
func (*MemoryConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{7}
}

func (x *MemoryConfig) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *MemoryConfig) GetPath() string {
	if x != nil {
		return x.Path
	}
	return ""
}

func (x *MemoryConfig) GetDsn() string {
	if x != nil {
		return x.Dsn
	}
	return ""
}

func (x *MemoryConfig) GetMaxHistory() int32 {
	if x != nil {
		return x.MaxHistory
	}
	return 0
}

func (x *MemoryConfig) GetMemoryCompression() *MemoryCompressionConfig {
	if x != nil {
		return x.MemoryCompression
	}
	return nil
}

// MemoryCompressionBatchSizes defines how many messages to compress in each batch
type MemoryCompressionBatchSizes struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of messages to compress in normal conditions (default: 3)
	Normal int32 `protobuf:"varint,1,opt,name=normal,proto3" json:"normal,omitempty"`
	// Number of messages to compress under warning threshold (default: 5)
	Warning int32 `protobuf:"varint,2,opt,name=warning,proto3" json:"warning,omitempty"`
	// Number of messages to compress under critical threshold (default: 7)
	Critical      int32 `protobuf:"varint,3,opt,name=critical,proto3" json:"critical,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MemoryCompressionBatchSizes) Reset() {
	*x = MemoryCompressionBatchSizes{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MemoryCompressionBatchSizes) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MemoryCompressionBatchSizes) ProtoMessage() {}

func (x *MemoryCompressionBatchSizes) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MemoryCompressionBatchSizes.ProtoReflect.Descriptor instead.
func (*MemoryCompressionBatchSizes) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{8}
}

func (x *MemoryCompressionBatchSizes) GetNormal() int32 {
	if x != nil {
		return x.Normal
	}
	return 0
}

func (x *MemoryCompressionBatchSizes) GetWarning() int32 {
	if x != nil {
		return x.Warning
	}
	return 0
}

func (x *MemoryCompressionBatchSizes) GetCritical() int32 {
	if x != nil {
		return x.Critical
	}
	return 0
}

// MemoryCompressionConfig defines conversation history compression behavior
type MemoryCompressionConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Workload profile (default: WORKLOAD_PROFILE_BALANCED)
	// Provides preset values for thresholds and limits
	WorkloadProfile WorkloadProfile `protobuf:"varint,1,opt,name=workload_profile,json=workloadProfile,proto3,enum=loom.v1.WorkloadProfile" json:"workload_profile,omitempty"`
	// Maximum messages in L1 cache before compression triggers (default: profile-dependent)
	// data_intensive=5, balanced=8, conversational=12
	MaxL1Messages int32 `protobuf:"varint,2,opt,name=max_l1_messages,json=maxL1Messages,proto3" json:"max_l1_messages,omitempty"`
	// Minimum messages in L1 cache after compression (default: max_l1_messages / 2)
	// Ensures L1 doesn't stay empty after aggressive compression
	MinL1Messages int32 `protobuf:"varint,3,opt,name=min_l1_messages,json=minL1Messages,proto3" json:"min_l1_messages,omitempty"`
	// Warning threshold as percentage (0-100) (default: profile-dependent)
	// data_intensive=50, balanced=60, conversational=70
	WarningThresholdPercent int32 `protobuf:"varint,4,opt,name=warning_threshold_percent,json=warningThresholdPercent,proto3" json:"warning_threshold_percent,omitempty"`
	// Critical threshold as percentage (0-100) (default: profile-dependent)
	// data_intensive=70, balanced=75, conversational=85
	CriticalThresholdPercent int32 `protobuf:"varint,5,opt,name=critical_threshold_percent,json=criticalThresholdPercent,proto3" json:"critical_threshold_percent,omitempty"`
	// Batch sizes for compression operations
	BatchSizes    *MemoryCompressionBatchSizes `protobuf:"bytes,6,opt,name=batch_sizes,json=batchSizes,proto3" json:"batch_sizes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MemoryCompressionConfig) Reset() {
	*x = MemoryCompressionConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MemoryCompressionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MemoryCompressionConfig) ProtoMessage() {}

func (x *MemoryCompressionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MemoryCompressionConfig.ProtoReflect.Descriptor instead.
func (*MemoryCompressionConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{9}
}

func (x *MemoryCompressionConfig) GetWorkloadProfile() WorkloadProfile {
	if x != nil {
		return x.WorkloadProfile
	}
	return WorkloadProfile_WORKLOAD_PROFILE_UNSPECIFIED
}

func (x *MemoryCompressionConfig) GetMaxL1Messages() int32 {
	if x != nil {
		return x.MaxL1Messages
	}
	return 0
}

func (x *MemoryCompressionConfig) GetMinL1Messages() int32 {
	if x != nil {
		return x.MinL1Messages
	}
	return 0
}

func (x *MemoryCompressionConfig) GetWarningThresholdPercent() int32 {
	if x != nil {
		return x.WarningThresholdPercent
	}
	return 0
}

func (x *MemoryCompressionConfig) GetCriticalThresholdPercent() int32 {
	if x != nil {
		return x.CriticalThresholdPercent
	}
	return 0
}

func (x *MemoryCompressionConfig) GetBatchSizes() *MemoryCompressionBatchSizes {
	if x != nil {
		return x.BatchSizes
	}
	return nil
}

// BehaviorConfig defines agent behavior constraints
type BehaviorConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Maximum tool call iterations per turn
	MaxIterations int32 `protobuf:"varint,1,opt,name=max_iterations,json=maxIterations,proto3" json:"max_iterations,omitempty"`
	// Timeout in seconds for each message
	TimeoutSeconds int32 `protobuf:"varint,2,opt,name=timeout_seconds,json=timeoutSeconds,proto3" json:"timeout_seconds,omitempty"`
	// Whether to allow code execution (security setting)
	AllowCodeExecution bool `protobuf:"varint,3,opt,name=allow_code_execution,json=allowCodeExecution,proto3" json:"allow_code_execution,omitempty"`
	// Allowed domains for web access (empty = all)
	AllowedDomains []string `protobuf:"bytes,4,rep,name=allowed_domains,json=allowedDomains,proto3" json:"allowed_domains,omitempty"`
	// Maximum conversation turns before forcing completion (default: 25)
	// A turn is one LLM call/response cycle. Complex tasks with many tool calls
	// may need higher values (e.g., 50-100).
	MaxTurns int32 `protobuf:"varint,5,opt,name=max_turns,json=maxTurns,proto3" json:"max_turns,omitempty"`
	// Maximum tool executions per conversation (default: 50)
	MaxToolExecutions int32 `protobuf:"varint,6,opt,name=max_tool_executions,json=maxToolExecutions,proto3" json:"max_tool_executions,omitempty"`
	// Pattern configuration for pattern-guided learning (optional)
	Patterns      *PatternConfig `protobuf:"bytes,7,opt,name=patterns,proto3" json:"patterns,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BehaviorConfig) Reset() {
	*x = BehaviorConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BehaviorConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BehaviorConfig) ProtoMessage() {}

func (x *BehaviorConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BehaviorConfig.ProtoReflect.Descriptor instead.
func (*BehaviorConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{10}
}

func (x *BehaviorConfig) GetMaxIterations() int32 {
	if x != nil {
		return x.MaxIterations
	}
	return 0
}

func (x *BehaviorConfig) GetTimeoutSeconds() int32 {
	if x != nil {
		return x.TimeoutSeconds
	}
	return 0
}

func (x *BehaviorConfig) GetAllowCodeExecution() bool {
	if x != nil {
		return x.AllowCodeExecution
	}
	return false
}

func (x *BehaviorConfig) GetAllowedDomains() []string {
	if x != nil {
		return x.AllowedDomains
	}
	return nil
}

func (x *BehaviorConfig) GetMaxTurns() int32 {
	if x != nil {
		return x.MaxTurns
	}
	return 0
}

func (x *BehaviorConfig) GetMaxToolExecutions() int32 {
	if x != nil {
		return x.MaxToolExecutions
	}
	return 0
}

func (x *BehaviorConfig) GetPatterns() *PatternConfig {
	if x != nil {
		return x.Patterns
	}
	return nil
}

// PatternConfig defines pattern-guided learning configuration
// Patterns provide domain-specific templates and best practices for common tasks
type PatternConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Enable pattern injection (default: true for v1.0.0)
	// When enabled, the orchestrator automatically selects and injects relevant patterns
	// into the LLM context based on user intent classification
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Minimum confidence threshold for pattern selection (0.0-1.0, default: 0.75)
	// Patterns with confidence below this threshold will be skipped
	// Higher values (0.8-0.9) reduce false positives but may miss relevant patterns
	// Lower values (0.5-0.7) increase recall but may inject irrelevant patterns
	MinConfidence float32 `protobuf:"fixed32,2,opt,name=min_confidence,json=minConfidence,proto3" json:"min_confidence,omitempty"`
	// Maximum patterns to inject per turn (default: 1)
	// Higher values provide more context but increase token usage
	// Recommended: 1-2 patterns to balance context and cost
	MaxPatternsPerTurn int32 `protobuf:"varint,3,opt,name=max_patterns_per_turn,json=maxPatternsPerTurn,proto3" json:"max_patterns_per_turn,omitempty"`
	// Enable pattern effectiveness tracking (default: true)
	// When enabled, records pattern usage metrics to learning database
	// Enables continuous learning and adaptive pattern selection
	EnableTracking bool `protobuf:"varint,4,opt,name=enable_tracking,json=enableTracking,proto3" json:"enable_tracking,omitempty"`
	// Use LLM-based intent classification (default: true for v1.0.2+)
	// When enabled, uses LLM to classify user intent for more accurate pattern selection
	// Trade-off: Higher accuracy (~90-95%) but adds ~300ms latency and ~$0.0001 cost per turn
	// Set to false for keyword-based classification (fast, no cost, but less accurate)
	UseLlmClassifier bool `protobuf:"varint,5,opt,name=use_llm_classifier,json=useLlmClassifier,proto3" json:"use_llm_classifier,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *PatternConfig) Reset() {
	*x = PatternConfig{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PatternConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PatternConfig) ProtoMessage() {}

func (x *PatternConfig) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PatternConfig.ProtoReflect.Descriptor instead.
func (*PatternConfig) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{11}
}

func (x *PatternConfig) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *PatternConfig) GetMinConfidence() float32 {
	if x != nil {
		return x.MinConfidence
	}
	return 0
}

func (x *PatternConfig) GetMaxPatternsPerTurn() int32 {
	if x != nil {
		return x.MaxPatternsPerTurn
	}
	return 0
}

func (x *PatternConfig) GetEnableTracking() bool {
	if x != nil {
		return x.EnableTracking
	}
	return false
}

func (x *PatternConfig) GetUseLlmClassifier() bool {
	if x != nil {
		return x.UseLlmClassifier
	}
	return false
}

// AgentTemplate defines a reusable agent template
type AgentTemplate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Template name (e.g., "expert", "code_reviewer")
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Template description
	Description string `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	// Template parameters
	Parameters []*TemplateParameter `protobuf:"bytes,3,rep,name=parameters,proto3" json:"parameters,omitempty"`
	// Template config with placeholders
	TemplateConfig *AgentConfig `protobuf:"bytes,4,opt,name=template_config,json=templateConfig,proto3" json:"template_config,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *AgentTemplate) Reset() {
	*x = AgentTemplate{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AgentTemplate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AgentTemplate) ProtoMessage() {}

func (x *AgentTemplate) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AgentTemplate.ProtoReflect.Descriptor instead.
func (*AgentTemplate) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{12}
}

func (x *AgentTemplate) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *AgentTemplate) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *AgentTemplate) GetParameters() []*TemplateParameter {
	if x != nil {
		return x.Parameters
	}
	return nil
}

func (x *AgentTemplate) GetTemplateConfig() *AgentConfig {
	if x != nil {
		return x.TemplateConfig
	}
	return nil
}

// TemplateParameter defines a template parameter
type TemplateParameter struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Parameter name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Parameter type: "string", "int", "float", "bool", "list"
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// Whether parameter is required
	Required bool `protobuf:"varint,3,opt,name=required,proto3" json:"required,omitempty"`
	// Default value (if not required)
	DefaultValue string `protobuf:"bytes,4,opt,name=default_value,json=defaultValue,proto3" json:"default_value,omitempty"`
	// Parameter description
	Description   string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TemplateParameter) Reset() {
	*x = TemplateParameter{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TemplateParameter) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TemplateParameter) ProtoMessage() {}

func (x *TemplateParameter) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TemplateParameter.ProtoReflect.Descriptor instead.
func (*TemplateParameter) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{13}
}

func (x *TemplateParameter) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *TemplateParameter) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *TemplateParameter) GetRequired() bool {
	if x != nil {
		return x.Required
	}
	return false
}

func (x *TemplateParameter) GetDefaultValue() string {
	if x != nil {
		return x.DefaultValue
	}
	return ""
}

func (x *TemplateParameter) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

// AgentProfile defines environment-specific configuration overrides
type AgentProfile struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Profile name (e.g., "development", "production")
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Default values for all agents
	Defaults *AgentConfig `protobuf:"bytes,2,opt,name=defaults,proto3" json:"defaults,omitempty"`
	// Per-agent overrides
	Overrides     map[string]*AgentConfig `protobuf:"bytes,3,rep,name=overrides,proto3" json:"overrides,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AgentProfile) Reset() {
	*x = AgentProfile{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AgentProfile) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AgentProfile) ProtoMessage() {}

func (x *AgentProfile) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AgentProfile.ProtoReflect.Descriptor instead.
func (*AgentProfile) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{14}
}

func (x *AgentProfile) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *AgentProfile) GetDefaults() *AgentConfig {
	if x != nil {
		return x.Defaults
	}
	return nil
}

func (x *AgentProfile) GetOverrides() map[string]*AgentConfig {
	if x != nil {
		return x.Overrides
	}
	return nil
}

// EphemeralAgentPolicy defines when and how to spawn ephemeral agents.
// Agents declare these policies to dynamically create other agents based on runtime conditions.
type EphemeralAgentPolicy struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Role name for the ephemeral agent (e.g., "judge", "domain_expert", "moderator")
	Role string `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"`
	// Trigger conditions that determine when to spawn this agent
	Trigger *SpawnTrigger `protobuf:"bytes,2,opt,name=trigger,proto3" json:"trigger,omitempty"`
	// Template configuration for the spawned agent
	Template *AgentConfig `protobuf:"bytes,3,opt,name=template,proto3" json:"template,omitempty"`
	// Maximum number of times this agent can be spawned per workflow
	MaxSpawns int32 `protobuf:"varint,4,opt,name=max_spawns,json=maxSpawns,proto3" json:"max_spawns,omitempty"`
	// Cost budget in USD (prevents runaway spawning)
	CostLimitUsd  float32 `protobuf:"fixed32,5,opt,name=cost_limit_usd,json=costLimitUsd,proto3" json:"cost_limit_usd,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EphemeralAgentPolicy) Reset() {
	*x = EphemeralAgentPolicy{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EphemeralAgentPolicy) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EphemeralAgentPolicy) ProtoMessage() {}

func (x *EphemeralAgentPolicy) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EphemeralAgentPolicy.ProtoReflect.Descriptor instead.
func (*EphemeralAgentPolicy) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{15}
}

func (x *EphemeralAgentPolicy) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *EphemeralAgentPolicy) GetTrigger() *SpawnTrigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *EphemeralAgentPolicy) GetTemplate() *AgentConfig {
	if x != nil {
		return x.Template
	}
	return nil
}

func (x *EphemeralAgentPolicy) GetMaxSpawns() int32 {
	if x != nil {
		return x.MaxSpawns
	}
	return 0
}

func (x *EphemeralAgentPolicy) GetCostLimitUsd() float32 {
	if x != nil {
		return x.CostLimitUsd
	}
	return 0
}

// SpawnTrigger defines conditions for spawning ephemeral agents
type SpawnTrigger struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Trigger type
	Type SpawnTriggerType `protobuf:"varint,1,opt,name=type,proto3,enum=loom.v1.SpawnTriggerType" json:"type,omitempty"`
	// Threshold value (interpretation depends on type)
	Threshold float32 `protobuf:"fixed32,2,opt,name=threshold,proto3" json:"threshold,omitempty"`
	// Optional: Custom condition expression (for extensibility)
	Condition     string `protobuf:"bytes,3,opt,name=condition,proto3" json:"condition,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpawnTrigger) Reset() {
	*x = SpawnTrigger{}
	mi := &file_loom_v1_agent_config_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpawnTrigger) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpawnTrigger) ProtoMessage() {}

func (x *SpawnTrigger) ProtoReflect() protoreflect.Message {
	mi := &file_loom_v1_agent_config_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpawnTrigger.ProtoReflect.Descriptor instead.
func (*SpawnTrigger) Descriptor() ([]byte, []int) {
	return file_loom_v1_agent_config_proto_rawDescGZIP(), []int{16}
}

func (x *SpawnTrigger) GetType() SpawnTriggerType {
	if x != nil {
		return x.Type
	}
	return SpawnTriggerType_SPAWN_TRIGGER_TYPE_UNSPECIFIED
}

func (x *SpawnTrigger) GetThreshold() float32 {
	if x != nil {
		return x.Threshold
	}
	return 0
}

func (x *SpawnTrigger) GetCondition() string {
	if x != nil {
		return x.Condition
	}
	return ""
}

var File_loom_v1_agent_config_proto protoreflect.FileDescriptor

const file_loom_v1_agent_config_proto_rawDesc = "" +
	"\n" +
	"\x1aloom/v1/agent_config.proto\x12\aloom.v1\"\xc1\a\n" +
	"\vAgentConfig\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x12$\n" +
	"\x03llm\x18\x03 \x01(\v2\x12.loom.v1.LLMConfigR\x03llm\x12#\n" +
	"\rsystem_prompt\x18\x04 \x01(\tR\fsystemPrompt\x12*\n" +
	"\x05tools\x18\x05 \x01(\v2\x14.loom.v1.ToolsConfigR\x05tools\x12-\n" +
	"\x06memory\x18\x06 \x01(\v2\x15.loom.v1.MemoryConfigR\x06memory\x123\n" +
	"\bbehavior\x18\a \x01(\v2\x17.loom.v1.BehaviorConfigR\bbehavior\x12>\n" +
	"\bmetadata\x18\b \x03(\v2\".loom.v1.AgentConfig.MetadataEntryR\bmetadata\x12H\n" +
	"\x10ephemeral_agents\x18\t \x03(\v2\x1d.loom.v1.EphemeralAgentPolicyR\x0fephemeralAgents\x12\x10\n" +
	"\x03rom\x18\n" +
	" \x01(\tR\x03rom\x12:\n" +
	"\x19enable_finding_extraction\x18\v \x01(\bR\x17enableFindingExtraction\x12-\n" +
	"\x12extraction_cadence\x18\f \x01(\x05R\x11extractionCadence\x12!\n" +
	"\fmax_findings\x18\r \x01(\x05R\vmaxFindings\x12/\n" +
	"\tjudge_llm\x18\x0e \x01(\v2\x12.loom.v1.LLMConfigR\bjudgeLlm\x12=\n" +
	"\x10orchestrator_llm\x18\x0f \x01(\v2\x12.loom.v1.LLMConfigR\x0forchestratorLlm\x129\n" +
	"\x0eclassifier_llm\x18\x10 \x01(\v2\x12.loom.v1.LLMConfigR\rclassifierLlm\x129\n" +
	"\x0ecompressor_llm\x18\x11 \x01(\v2\x12.loom.v1.LLMConfigR\rcompressorLlm\x12'\n" +
	"\x0factive_provider\x18\x12 \x01(\tR\x0eactiveProvider\x12+\n" +
	"\x11allowed_providers\x18\x13 \x03(\tR\x10allowedProviders\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"O\n" +
	"\rProviderEntry\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12*\n" +
	"\x06config\x18\x02 \x01(\v2\x12.loom.v1.LLMConfigR\x06config\"\\\n" +
	"\fProviderPool\x124\n" +
	"\tproviders\x18\x01 \x03(\v2\x16.loom.v1.ProviderEntryR\tproviders\x12\x16\n" +
	"\x06active\x18\x02 \x01(\tR\x06active\"\xb3\x02\n" +
	"\tLLMConfig\x12\x1a\n" +
	"\bprovider\x18\x01 \x01(\tR\bprovider\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12 \n" +
	"\vtemperature\x18\x03 \x01(\x02R\vtemperature\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x04 \x01(\x05R\tmaxTokens\x12%\n" +
	"\x0estop_sequences\x18\x05 \x03(\tR\rstopSequences\x12\x13\n" +
	"\x05top_p\x18\x06 \x01(\x02R\x04topP\x12\x13\n" +
	"\x05top_k\x18\a \x01(\x05R\x04topK\x12,\n" +
	"\x12max_context_tokens\x18\b \x01(\x05R\x10maxContextTokens\x124\n" +
	"\x16reserved_output_tokens\x18\t \x01(\x05R\x14reservedOutputTokens\"\x84\x01\n" +
	"\vToolsConfig\x12(\n" +
	"\x03mcp\x18\x01 \x03(\v2\x16.loom.v1.MCPToolConfigR\x03mcp\x121\n" +
	"\x06custom\x18\x02 \x03(\v2\x19.loom.v1.CustomToolConfigR\x06custom\x12\x18\n" +
	"\abuiltin\x18\x03 \x03(\tR\abuiltin\"=\n" +
	"\rMCPToolConfig\x12\x16\n" +
	"\x06server\x18\x01 \x01(\tR\x06server\x12\x14\n" +
	"\x05tools\x18\x02 \x03(\tR\x05tools\"N\n" +
	"\x10CustomToolConfig\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12&\n" +
	"\x0eimplementation\x18\x02 \x01(\tR\x0eimplementation\"\xba\x01\n" +
	"\fMemoryConfig\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x12\n" +
	"\x04path\x18\x02 \x01(\tR\x04path\x12\x10\n" +
	"\x03dsn\x18\x03 \x01(\tR\x03dsn\x12\x1f\n" +
	"\vmax_history\x18\x04 \x01(\x05R\n" +
	"maxHistory\x12O\n" +
	"\x12memory_compression\x18\x05 \x01(\v2 .loom.v1.MemoryCompressionConfigR\x11memoryCompression\"k\n" +
	"\x1bMemoryCompressionBatchSizes\x12\x16\n" +
	"\x06normal\x18\x01 \x01(\x05R\x06normal\x12\x18\n" +
	"\awarning\x18\x02 \x01(\x05R\awarning\x12\x1a\n" +
	"\bcritical\x18\x03 \x01(\x05R\bcritical\"\xef\x02\n" +
	"\x17MemoryCompressionConfig\x12C\n" +
	"\x10workload_profile\x18\x01 \x01(\x0e2\x18.loom.v1.WorkloadProfileR\x0fworkloadProfile\x12&\n" +
	"\x0fmax_l1_messages\x18\x02 \x01(\x05R\rmaxL1Messages\x12&\n" +
	"\x0fmin_l1_messages\x18\x03 \x01(\x05R\rminL1Messages\x12:\n" +
	"\x19warning_threshold_percent\x18\x04 \x01(\x05R\x17warningThresholdPercent\x12<\n" +
	"\x1acritical_threshold_percent\x18\x05 \x01(\x05R\x18criticalThresholdPercent\x12E\n" +
	"\vbatch_sizes\x18\x06 \x01(\v2$.loom.v1.MemoryCompressionBatchSizesR\n" +
	"batchSizes\"\xbc\x02\n" +
	"\x0eBehaviorConfig\x12%\n" +
	"\x0emax_iterations\x18\x01 \x01(\x05R\rmaxIterations\x12'\n" +
	"\x0ftimeout_seconds\x18\x02 \x01(\x05R\x0etimeoutSeconds\x120\n" +
	"\x14allow_code_execution\x18\x03 \x01(\bR\x12allowCodeExecution\x12'\n" +
	"\x0fallowed_domains\x18\x04 \x03(\tR\x0eallowedDomains\x12\x1b\n" +
	"\tmax_turns\x18\x05 \x01(\x05R\bmaxTurns\x12.\n" +
	"\x13max_tool_executions\x18\x06 \x01(\x05R\x11maxToolExecutions\x122\n" +
	"\bpatterns\x18\a \x01(\v2\x16.loom.v1.PatternConfigR\bpatterns\"\xda\x01\n" +
	"\rPatternConfig\x12\x18\n" +
	"\aenabled\x18\x01 \x01(\bR\aenabled\x12%\n" +
	"\x0emin_confidence\x18\x02 \x01(\x02R\rminConfidence\x121\n" +
	"\x15max_patterns_per_turn\x18\x03 \x01(\x05R\x12maxPatternsPerTurn\x12'\n" +
	"\x0fenable_tracking\x18\x04 \x01(\bR\x0eenableTracking\x12,\n" +
	"\x12use_llm_classifier\x18\x05 \x01(\bR\x10useLlmClassifier\"\xc0\x01\n" +
	"\rAgentTemplate\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x12:\n" +
	"\n" +
	"parameters\x18\x03 \x03(\v2\x1a.loom.v1.TemplateParameterR\n" +
	"parameters\x12=\n" +
	"\x0ftemplate_config\x18\x04 \x01(\v2\x14.loom.v1.AgentConfigR\x0etemplateConfig\"\x9e\x01\n" +
	"\x11TemplateParameter\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x1a\n" +
	"\brequired\x18\x03 \x01(\bR\brequired\x12#\n" +
	"\rdefault_value\x18\x04 \x01(\tR\fdefaultValue\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\"\xec\x01\n" +
	"\fAgentProfile\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x120\n" +
	"\bdefaults\x18\x02 \x01(\v2\x14.loom.v1.AgentConfigR\bdefaults\x12B\n" +
	"\toverrides\x18\x03 \x03(\v2$.loom.v1.AgentProfile.OverridesEntryR\toverrides\x1aR\n" +
	"\x0eOverridesEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12*\n" +
	"\x05value\x18\x02 \x01(\v2\x14.loom.v1.AgentConfigR\x05value:\x028\x01\"\xd2\x01\n" +
	"\x14EphemeralAgentPolicy\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12/\n" +
	"\atrigger\x18\x02 \x01(\v2\x15.loom.v1.SpawnTriggerR\atrigger\x120\n" +
	"\btemplate\x18\x03 \x01(\v2\x14.loom.v1.AgentConfigR\btemplate\x12\x1d\n" +
	"\n" +
	"max_spawns\x18\x04 \x01(\x05R\tmaxSpawns\x12$\n" +
	"\x0ecost_limit_usd\x18\x05 \x01(\x02R\fcostLimitUsd\"y\n" +
	"\fSpawnTrigger\x12-\n" +
	"\x04type\x18\x01 \x01(\x0e2\x19.loom.v1.SpawnTriggerTypeR\x04type\x12\x1c\n" +
	"\tthreshold\x18\x02 \x01(\x02R\tthreshold\x12\x1c\n" +
	"\tcondition\x18\x03 \x01(\tR\tcondition*\x98\x01\n" +
	"\aLLMRole\x12\x18\n" +
	"\x14LLM_ROLE_UNSPECIFIED\x10\x00\x12\x12\n" +
	"\x0eLLM_ROLE_AGENT\x10\x01\x12\x12\n" +
	"\x0eLLM_ROLE_JUDGE\x10\x02\x12\x19\n" +
	"\x15LLM_ROLE_ORCHESTRATOR\x10\x03\x12\x17\n" +
	"\x13LLM_ROLE_CLASSIFIER\x10\x04\x12\x17\n" +
	"\x13LLM_ROLE_COMPRESSOR\x10\x05*\x9c\x01\n" +
	"\x0fWorkloadProfile\x12 \n" +
	"\x1cWORKLOAD_PROFILE_UNSPECIFIED\x10\x00\x12\x1d\n" +
	"\x19WORKLOAD_PROFILE_BALANCED\x10\x01\x12#\n" +
	"\x1fWORKLOAD_PROFILE_DATA_INTENSIVE\x10\x02\x12#\n" +
	"\x1fWORKLOAD_PROFILE_CONVERSATIONAL\x10\x03*\xab\x01\n" +
	"\x10SpawnTriggerType\x12\"\n" +
	"\x1eSPAWN_TRIGGER_TYPE_UNSPECIFIED\x10\x00\x12\x19\n" +
	"\x15CONSENSUS_NOT_REACHED\x10\x01\x12\x14\n" +
	"\x10CONFIDENCE_BELOW\x10\x02\x12\x10\n" +
	"\fTIE_DETECTED\x10\x03\x12\x18\n" +
	"\x14ESCALATION_REQUESTED\x10\x04\x12\n" +
	"\n" +
	"\x06ALWAYS\x10\x05\x12\n" +
	"\n" +
	"\x06CUSTOM\x10\x06B5Z3github.com/teradata-labs/loom/gen/go/loom/v1;loomv1b\x06proto3"

var (
	file_loom_v1_agent_config_proto_rawDescOnce sync.Once
	file_loom_v1_agent_config_proto_rawDescData []byte
)

func file_loom_v1_agent_config_proto_rawDescGZIP() []byte {
	file_loom_v1_agent_config_proto_rawDescOnce.Do(func() {
		file_loom_v1_agent_config_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_loom_v1_agent_config_proto_rawDesc), len(file_loom_v1_agent_config_proto_rawDesc)))
	})
	return file_loom_v1_agent_config_proto_rawDescData
}

var file_loom_v1_agent_config_proto_enumTypes = make([]protoimpl.EnumInfo, 3)
var file_loom_v1_agent_config_proto_msgTypes = make([]protoimpl.MessageInfo, 19)
var file_loom_v1_agent_config_proto_goTypes = []any{
	(LLMRole)(0),                        // 0: loom.v1.LLMRole
	(WorkloadProfile)(0),                // 1: loom.v1.WorkloadProfile
	(SpawnTriggerType)(0),               // 2: loom.v1.SpawnTriggerType
	(*AgentConfig)(nil),                 // 3: loom.v1.AgentConfig
	(*ProviderEntry)(nil),               // 4: loom.v1.ProviderEntry
	(*ProviderPool)(nil),                // 5: loom.v1.ProviderPool
	(*LLMConfig)(nil),                   // 6: loom.v1.LLMConfig
	(*ToolsConfig)(nil),                 // 7: loom.v1.ToolsConfig
	(*MCPToolConfig)(nil),               // 8: loom.v1.MCPToolConfig
	(*CustomToolConfig)(nil),            // 9: loom.v1.CustomToolConfig
	(*MemoryConfig)(nil),                // 10: loom.v1.MemoryConfig
	(*MemoryCompressionBatchSizes)(nil), // 11: loom.v1.MemoryCompressionBatchSizes
	(*MemoryCompressionConfig)(nil),     // 12: loom.v1.MemoryCompressionConfig
	(*BehaviorConfig)(nil),              // 13: loom.v1.BehaviorConfig
	(*PatternConfig)(nil),               // 14: loom.v1.PatternConfig
	(*AgentTemplate)(nil),               // 15: loom.v1.AgentTemplate
	(*TemplateParameter)(nil),           // 16: loom.v1.TemplateParameter
	(*AgentProfile)(nil),                // 17: loom.v1.AgentProfile
	(*EphemeralAgentPolicy)(nil),        // 18: loom.v1.EphemeralAgentPolicy
	(*SpawnTrigger)(nil),                // 19: loom.v1.SpawnTrigger
	nil,                                 // 20: loom.v1.AgentConfig.MetadataEntry
	nil,                                 // 21: loom.v1.AgentProfile.OverridesEntry
}
var file_loom_v1_agent_config_proto_depIdxs = []int32{
	6,  // 0: loom.v1.AgentConfig.llm:type_name -> loom.v1.LLMConfig
	7,  // 1: loom.v1.AgentConfig.tools:type_name -> loom.v1.ToolsConfig
	10, // 2: loom.v1.AgentConfig.memory:type_name -> loom.v1.MemoryConfig
	13, // 3: loom.v1.AgentConfig.behavior:type_name -> loom.v1.BehaviorConfig
	20, // 4: loom.v1.AgentConfig.metadata:type_name -> loom.v1.AgentConfig.MetadataEntry
	18, // 5: loom.v1.AgentConfig.ephemeral_agents:type_name -> loom.v1.EphemeralAgentPolicy
	6,  // 6: loom.v1.AgentConfig.judge_llm:type_name -> loom.v1.LLMConfig
	6,  // 7: loom.v1.AgentConfig.orchestrator_llm:type_name -> loom.v1.LLMConfig
	6,  // 8: loom.v1.AgentConfig.classifier_llm:type_name -> loom.v1.LLMConfig
	6,  // 9: loom.v1.AgentConfig.compressor_llm:type_name -> loom.v1.LLMConfig
	6,  // 10: loom.v1.ProviderEntry.config:type_name -> loom.v1.LLMConfig
	4,  // 11: loom.v1.ProviderPool.providers:type_name -> loom.v1.ProviderEntry
	8,  // 12: loom.v1.ToolsConfig.mcp:type_name -> loom.v1.MCPToolConfig
	9,  // 13: loom.v1.ToolsConfig.custom:type_name -> loom.v1.CustomToolConfig
	12, // 14: loom.v1.MemoryConfig.memory_compression:type_name -> loom.v1.MemoryCompressionConfig
	1,  // 15: loom.v1.MemoryCompressionConfig.workload_profile:type_name -> loom.v1.WorkloadProfile
	11, // 16: loom.v1.MemoryCompressionConfig.batch_sizes:type_name -> loom.v1.MemoryCompressionBatchSizes
	14, // 17: loom.v1.BehaviorConfig.patterns:type_name -> loom.v1.PatternConfig
	16, // 18: loom.v1.AgentTemplate.parameters:type_name -> loom.v1.TemplateParameter
	3,  // 19: loom.v1.AgentTemplate.template_config:type_name -> loom.v1.AgentConfig
	3,  // 20: loom.v1.AgentProfile.defaults:type_name -> loom.v1.AgentConfig
	21, // 21: loom.v1.AgentProfile.overrides:type_name -> loom.v1.AgentProfile.OverridesEntry
	19, // 22: loom.v1.EphemeralAgentPolicy.trigger:type_name -> loom.v1.SpawnTrigger
	3,  // 23: loom.v1.EphemeralAgentPolicy.template:type_name -> loom.v1.AgentConfig
	2,  // 24: loom.v1.SpawnTrigger.type:type_name -> loom.v1.SpawnTriggerType
	3,  // 25: loom.v1.AgentProfile.OverridesEntry.value:type_name -> loom.v1.AgentConfig
	26, // [26:26] is the sub-list for method output_type
	26, // [26:26] is the sub-list for method input_type
	26, // [26:26] is the sub-list for extension type_name
	26, // [26:26] is the sub-list for extension extendee
	0,  // [0:26] is the sub-list for field type_name
}

func init() { file_loom_v1_agent_config_proto_init() }
func file_loom_v1_agent_config_proto_init() {
	if File_loom_v1_agent_config_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_loom_v1_agent_config_proto_rawDesc), len(file_loom_v1_agent_config_proto_rawDesc)),
			NumEnums:      3,
			NumMessages:   19,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_loom_v1_agent_config_proto_goTypes,
		DependencyIndexes: file_loom_v1_agent_config_proto_depIdxs,
		EnumInfos:         file_loom_v1_agent_config_proto_enumTypes,
		MessageInfos:      file_loom_v1_agent_config_proto_msgTypes,
	}.Build()
	File_loom_v1_agent_config_proto = out.File
	file_loom_v1_agent_config_proto_goTypes = nil
	file_loom_v1_agent_config_proto_depIdxs = nil
}
